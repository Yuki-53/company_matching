# Описание пайплайна

Предварительно происходит адаптация данных под задачу: 
Данные разбиваются на трейн (не используется, так как использовалась при обучении модели), базу данных(по колонке "name_2" производится поиск) и запросы(колонка "name_1" используется для тестовых запросов)

Запрос матчится с каждым названием из базы данных и рассчитываются фичи для пары

В качестве демонстрации сделан не ввод одного названия, а автоматический тест части запросов

Результаты выполнения сортируются и в качестве ответа берутся топ k названий

После выполнения выводятся метрики accuracy top k для различных k (Считается что модель выдала верный результат, если в списке есть компания, для которой в датасете значение "is_duplicate" = 1)

# Метрики

При обучении моделей задача рассматривалась как классификация, и использовались метрики precision, recall и F1, как подходящие для несбалансированных выборок

В инференсе задача позиционируется как задача ранжирования, и используется метрика accuracy top k. Можно также использовать метрику recall top k, так как для одного запроса могут быть несколько релевантных названий, но из-за особенностей предоставленных данных таких вариантов в данном случае не будет.

# Препроцессинг

Приведение к нижнему регистру и удаление лишних символов

# Модели

*Какие модели пробовали:*

KNN, Catboost, Fasttext, Bert

Идея с KNN не сработала - плохое качество

Catboost + нагенеренные фичи оказался в финальном решении

Эмбеддинги fasttext не давали прироста в качестве по сравнению с catboost моделью

Инференс Bert показался слишком долгим 


*Какие фичи пробовали генерить:*

Количество символов, количество слов, пересечения слов, нормализованное расстояние Левенштейна, расстояние Дамерау-Левенштейна, 2- и 3-граммы, расстояние Жаккарда, SequenceMatcher (difflib), fuzzywuzzy, эмбеддинги fasttext и bert, tf-idf

При генерации фичей обращали внимание на распределения признаков:

вставить фото

В итоге откинули часть фичей которые не добавляли к качеству или долго рассчитывались для более быстрого инференса

Подробнее можно посмотреть в `./experiments/`

# Гиперпараметры

Обучали catboost 5000 эпох с early_stopping_rounds = 500, чтобы недопустить переобучение и сэкономить время

Выбор lr отдали catboost

Также установили вес для класса 1 равный 10, чтобы сгладить несбалансированность

# Оценка качества

Для задачи классификации:

f1: 0.91

recall: 0.893

precision 0.926

Если использовать "долгие" фичи:

f1: 0.914

recall: 0.915

precision 0.913

Для задачи ранжирования:  

top 5 accuracy score: 0.4

top 10 accuracy score: 0.5 

top 20 accuracy score: 0.68  

top 50 accuracy score: 0.79   

database size - 10000  
s
test size - 38  

# Оборудование

CPU, 16 gb RAM

Для работы не требуется GPU

# Производительность модели

При размере базы данных = 100к инференс происходит за ~ 10 с. на intel core i5 7300hq 2.5 ггц (довольно слабый проц)

# Масштабирование решения

Масштабирования можно добиться распараллеливанием вычислений на несколько cpu
